\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{A Comparison of Different Computer Vision Methods and Algorithms for the
    Classification of Aquatic Macroinvertebrates\\
{\footnotesize \textsuperscript{*}A Computer Vision project for the Department
of Engineering at Aarhus University}
}

\author{\IEEEauthorblockN{Th\'{e}o Morales}
\IEEEauthorblockA{\textit{MSc. Student of Computer Engineering} \\
\textit{Faculty of Science and Technology, Department of Engineering}\\
Aarhus University, Denmark \\
theo.martin.morales@post.au.dk}
}

\maketitle

\begin{abstract}
    Measuring water quality in natural environments can be a difficult problem to tackle. One of the ways of assessing the quality of fresh water in such environment is to observe and analyse the different aquatic macroinvertebrates that live in it. Using modern Computer Vision methods to do so is inherently more efficient, in terms of time and cost, than relying on the sole human expertise. Developing proper techniques in order to achieve similar, if not better, results than manual observation and analysis is the ultimate goal of this research. In this paper, a subset of the original dataset is used to conduct independent research on different image classification algorithms, and to compare several common ones with the state of the art Convolutional Neural Networks.
\end{abstract}

\begin{IEEEkeywords}
    CNN, Deep Neural Network, image classification, computer vision, machine learning
\end{IEEEkeywords}

\section{Introduction}
Ensuring the quality of water sources is an important task for the good of a human population, as well as the one of its surrounding ecosystem. Water can be infected with all sorts of bacteria, but can also contain a significant amount of micro-organisms that wouldn't be suited for human consumption, but nevertheless being part of a natural aquatic ecosystem that could be seen as a gage of quality and sanity.

However, measuring such concept isn't as trivial as what is commonly done with regular metrics, and it requires more reasoning and analysing than most standard measures in the scientific domain do. This study focuses on the analysis of known aquatic macroinvertebrates, which are part of aquatic ecosystems in water sources, and their automated classification using a machine learning approach. The end goal is to provide a reliable method for this task, that would ultimately surpass the human expertise in the field. In this paper, a set of well known and commonly used machine learning and computer vision methods are presented, and their results are compared and discussed after application on the dataset; the famous state-of-the-art Convolutional Neural Network will be used as a reference point in the benchmark.

\section{Dataset}

\subsection{Dataset presentation}
The provided dataset contains a subset of the whole dataset from the original research paper that this project leans on. It contains \textbf{5830} \emph{Training} samples, \textbf{2298} \emph{Validation} samples, and \textbf{3560} \emph{Test} samples. These sets are given in two forms:
\begin{itemize}
    \item the original images in color with a \textbf{\textsc{28x28}} pixel dimension, in the JPEG format
    \item the abstract representations of the images as a set of 4096-dimensional vectors (available inn \emph{CSV}, \emph{Matlab} and \emph{text} formats), obtained after feeding the base pictures to a CNN, pre-trained on the training dataset
\end{itemize}

\begin{figure}[htbp]
    \centerline{\includegraphics[height=4cm]{sample_macrobitches}}
    \caption{Four samples from Baetis niger (top) and Ameletus inopinatus (bottom) classes.}
    \label{fig}
\end{figure}

It goes without saying that each set also comes with its corresponding labels definition (available in \emph{CSV}, \emph{Matlab} and \emph{text} formats), except for the \emph{Test} dataset which labels, of course, need to be "guessed" by the classifier.


\subsection{Dataset pre-processing}
One important thing to mention is that the given JPEG pictures are already cropped to focus on the target object, thus minimizing the need for data pre-processing in some cases where not much needs to be done. For example, with computer vision methods such as \emph{SIFT} or \emph{HOG} features classification, a minimal amount of data preparation is necessary for the algorithms to be effective: vector normalization is often just enough. In this study, the \emph{Feature Scaling} normalization technique is used, in order to bring all the dataset's values into the range [0,1]:

\begin{equation}
    x_{new}=\frac{x_i-\min(x)}{\max(x)-\min(x)}
\end{equation}

With $x_i$ being the current value of the sample (a vector in this case), $\min(x)$ being the minimum value of the current dataset, and $\max(x)$ being the maximum value of the same dataset. This technique is useful when the classifier is computing a lot of multiplications, since it greatly reduces the difference between the two products when the multiplied values are very close to each other, thus restraining the scatter of the samples.

Data standardization can also be used in order to improve the classification results, by reducing the mean and unit variance to zero, using the following equation:

\begin{equation}
    x_{new}=\frac{x_i-\mu}{\sigma}
\end{equation}

Where $\mu$ is the mean of the dataset, and $\sigma$ is the variance of the same dataset. 

Concerning the Convolutional Neural Networks approach, a few more things have to be taken into consideration. In this project, a pre-trained CNN is used for fine-tuning over this dataset, meaning that the weights of the convolution layers are unchanged. This implies that the images fed into the network must be the same size as the ones it has been trained with. Without going into further details (more will be explained in the appropriate section), the JPEG images for this dataset had to be scaled up to match the network's input layer (\textsc{299x299} pixels), and some distortion is applied to the \emph{Training} images. Other than that, each image is normalized as previously explained.

\subsection{Dataset augmentation}
As stated above, \emph{Dataset Augmentation} is a process that is only applied to images used for a Convolutional Neural Network training phase, because it is the classifier that takes the most advantage of the three color channels of an image. It is only useful to augment the \emph{Training} sample images, since those are the only ones that will help the classifier to learn.
The \emph{Python} script provided by \emph{Tensorflow} for \emph{Inception Resnet v2} tales care of distorting images in order to augment the data set, to ultimately make the network invariant to aspects of the image that do not effect the label. Since the aspect ratio is not respected, and since the resizing method changes depending on the running thread number, the resizing operation may distort the images in a first place. Secondly, each image is randomly flipped horizontally. Finally, the colors are randomly distorted in four different ways.

\section{Methods and algorithms}
Classifying images of such similar shapes can be a difficult task to solve as a machine learning problem, and that is why several algorithms and methods must be applied on the same dataset in order to have a certain order of comparison to be able to conclude useful deductions.
Finding the right method to properly classify the dataset is the ultimate goal, but before simply going for the state-of-the-art CNN, it is best to study the well known methods and understand why one performs better than an other, in an attempt to apply the best possible approach.

The following algorithms have been applied and compared against each other:
\begin{itemize}
    \item \textbf{Multi Layer Perceptron Neural Network}
    \item \textbf{Pre-Trained Convolutional Neural Network}
    \item \textbf{Support Vector Machine with Bag Of Features}
    \item \textbf{Nearest Neighbour with Bag Of Features}
\end{itemize}

Those algorithms were implemented in \emph{Python 3}, with the help of the great libraries \emph{Tensorflow} and \emph{OpenCV}. In the following section, they will be presented and explained thoroughly, after what their results will be compared on the same basis. \emph{Note that the given accuracy corresponds to the validation accuracy, and that it may vary if measured on the test dataset.}

\subsection{Multi Layer Perceptron Neural Network}
    Famously known for being able to optimize a large range of cost functions, the MLP Neural Network does not need to be presented. The thing that makes it a very good candidate against the convolutional type is its fully-connected architecture, that is part of the actual CNN architecture as being the last "step".
Since the feature vectors provided in the dataset were produced by a CNN, it should be intuitive to think that feeding those into an independent MLP would produce rather similar results, and that is why it can be assumed that both scores should be close to each other.

The MLP has been trained from scratch using different architecures for the hidden layers, and with two different stochastic optimizers: \emph{Adam} and \emph{Stochastic Gradient Descent}, both with similar learning rates.
As for the activation function, $ReLU$ (for Rectified Linear Units) is used for the hidden layers, which, as research has shown \cite{b1}, results in much faster training for large network and is more similar to an actual neuron in the human brain.

\begin{equation}
    f(x) = \max(x, 0)
\end{equation}

However for the output layer, the $Softmax$ activation function was used, since it is more suited to deal with classification problems \cite{b2}. It works similarly to $Sigmoid$, in a way that it will squash the inputs to be between 0 and 1, but it is more equivalent to a categorical probability distribution:

\begin{equation}
    \sigma(z)_j = \frac{e^{z_j}}{{\sum\limits_{k=1}}^k e^{z_k}}
\end{equation}

Different results can be observed after tinkering with the hyperparameters, before obtaining what is to be considered the optimal configuration for the last row of the table:

\begin{table}[htbp]
\caption{Multi Layer Perceptron: \\ Hyperparameters and Configurations}
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{3}{|c|}{\textbf{Hyperparameters}}&\textbf{Final} \\
\cline{1-3} 
\textbf{\textit{Hidden Neurons}}& \textbf{\textit{Learn. Rate}}& \textbf{\textit{Batch Size}} & \textbf{\textit{Accuracy}} \\
\hline
2048:1024& 0.0018 & 50 & 72\% \\
\hline
\end{tabular}
\label{tab1}
\end{center}
\end{table}


\subsection{Pre-Trained Convolutional Neural Network}
    As previously explained, using a pre-trained Convolutional Neural Network has the big advantage of providing well-performing convolution layers, which play the biggest part in image classification for such a type of neural network.
    The chosen CNN is \emph{Inception Resnet V2}, that is part of \emph{Tensorflow-slim}'s research architectures and one of the top performing CNNs out there, according to \emph{Google}'s research \cite{b3}.

A checkpoint of that network, containing all the weights and biases, was downloaded and used to transfer the learning of the model, by keeping the convolution layers's weights but dropping the fully-connected layers's ones, in order to fine-tune the network with the macroinvertebrates dataset.
This was done fairly easily thanks to the good usability of the framework, and as stated above, a pre-processing script is provided for the images to be fitted into the network's input configuration.

This method is allegedly the best in the field, and if used well, can yield impressive results of accuracy above 95\%. However, since the computation of such network (especially on a large model like \emph{Inception}) is very slow and requires a recent GPU with CUDA capabilities, it has been hard to obtain decent results that would support the theory.

\subsection{Support Vector Machine with Bag Of Features}
    The vectors provided in each partition of the dataset were produced by a CNN trained on thousands of classes, which means the convolution filters are able to recognize all sorts of shapes very well.
Those feature or shape vectors can be directly classified and it would be reliable, however it is interesting to see if a nearly good result can be achieved with engineered features: features that are found in images using efficient algorithms.

    A \emph{Support Vector Machine} has been trained on the features obtained by the CNN, and another one by SIFT features computed from the original images, using the Bag Of Features (or Bag Of Words) technique.

\paragraph{CNN Features with SVM}
    Firstly, the given vectors were used to train an SVM using the kernel trick. The comparison between a linear SVM and a kernel SVM (using the \emph{rbf} kernel) can be seen in the following table:
end{table}

Without surprise, the kernel SVM performs better, and normalizing the data helped improve the final accuracy a little.

\paragraph{SIFT Features with SVM}
Secondly, features have been extracted "manually" using the \emph{Scale-Invariant Feature Transform} (SIFT) computer vision algorithm, with the \emph{OpenCV} library.a
This algorithm can be resumed in 6 steps:

\begin{enumerate}
\item Image scale-space generation using \emph{Gaussian Blur}
\item \emph{Difference Of Gaussians} (DOG) computation
\item DOG extremas location and interpolation (to find correct subpixels)
\item Interest point suppression by threshold
\item Gradient orientation extraction from interet point neighbourhood
\item Invarient feature descriptor generation
\end{enumerate}

After obtaining the SIFT features, the Bag Of Features technique is used to generate histograms of a consistent size, by clustering the feature descriptors using \emph{K-Means}.
Those histograms can then be classified, using an SVM in this current example.

\subsection{Nearest Neighbour with Bag Of Features}
The \emph{Nearest Neighbour} algorithm is very simple and simply consists in comparing each testing vector (here the histogram obtained after BoF) with every training vector, using the euclidian distance defined as:

\begin{equation}
    d_E(y,x) = ||y - x||_2 = \sqrt{(y - x)^\intercal(y-x)}
\end{equation}

The shortest distance is then used to attribute the sample the label of the winning candidate.

\paragraph{CNN Features with Nearest Neighbour}
    Using the same process:
Normalization also helps improving the accuracy.


\paragraph{SIFT Features with Nearest Neighbour}
    For the \emph{Nearest Neighbour} algorithm, the process is very similar: apply Bag Of Features on the SIFT features, then classify them with the algorithm.


\begin{thebibliography}{00}
\bibitem{b1} A. Krizhevsky, I. Sutskever, G. E. Hinton, ``ImageNet Classification with Deep Convolutional Neural Networks,'' http://www.cs.toronto.edu/%7Efritz/absps/imagenet.pdf, Toronto University
\bibitem{b2} Ji Yang, ``ReLU and Softmax Activation Functions,'' https://github.com/Kulbear/deep-learning-nano-foundation/wiki/ReLU-and-Softmax-Activation-Functions, 2017
\bibitem{b3} Tensorflow, ``TensorFlow-Slim image classification model library,'' https://github.com/tensorflow/models/tree/master/research/slim
\end{thebibliography}
\vspace{12pt}
\color{red}

\end{document}
